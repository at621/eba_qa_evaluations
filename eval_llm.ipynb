{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ec3b5c-e5b1-46fb-8f6f-4fadf389cfa5",
   "metadata": {},
   "source": [
    "## EBA Q&A evaluations\n",
    "\n",
    "This notebook evaluates the performance of a language model (LLM) for regulatory question-answering tasks. \n",
    "\n",
    "**Below is a summary of the steps and methods applied:**\n",
    "\n",
    "This notebook evaluates the performance of a language model (LLM) for regulatory question-answering tasks.  \n",
    "Prompts are then designed for two purposes: generating answers based on regulatory documents with references  \n",
    "and evaluating the quality of those answers through correctness and clarity ratings.\n",
    "\n",
    "Data is loaded from a YAML file (dod_eba.yaml), which contains question, context, and expert answers. Using the  \n",
    "LLM, answers are generated for each question, guided by the provided context. These responses are evaluated against  \n",
    "expert answers for correctness (alignment with the expert's response) and clarity (readability for humans). Ratings,  \n",
    "along with justifications, are recorded during this process.\n",
    "\n",
    "The results, including questions, LLM-generated answers, expert answers, ratings, and justifications, are compiled  \n",
    "into a pandas DataFrame for analysis. An example review process is included to allow detailed inspection of individual  \n",
    "questions, answers, and justifications. Insights from the evaluation highlight the alignment between LLM and expert  \n",
    "responses while also pointing out areas where the LLM could improve, such as addressing institutional policies and  \n",
    "regulatory nuances more explicitly.\n",
    "\n",
    "The questions originate from the EBA Single Rulebook Q&A, and some code snippets are adapted from OpenAI's Cookbook.\n",
    "\n",
    "#### References:\n",
    "- Questions were obtained from the [EBA Single Rulebook Q&A](https://www.eba.europa.eu/single-rule-book-qa).\n",
    "- Code snippets for prompt formatting and API usage were adapted from [OpenAI's Cookbook examples](https://github.com/openai/openai-cookbook/tree/main/examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bae6bf3-46df-47a4-8898-3dbba82dd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from openai import OpenAI\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145a074-3b1a-49ae-a9be-afe2417ab441",
   "metadata": {},
   "source": [
    "### A. Prepare prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a2e342-27b2-4779-84c4-6a2afe26b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rater prompt\n",
    "RATER_PROMPT = \"\"\"\\\n",
    "You are comparing a submitted answer to an expert answer on a given question. \n",
    "\n",
    "Here is the data:\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[Question]: {question}\n",
    "************\n",
    "[Context]: {context}\n",
    "************\n",
    "[Expert]: {expected}\n",
    "************\n",
    "[Submission]: {output}\n",
    "************\n",
    "[END DATA]\n",
    "\n",
    "Compare the factual content of the submitted answer with the expert answer. Ignore any differences in style, grammar, or punctuation.\n",
    "Rate the factual correctness on a scale of 1 to 10. Rate clarity on a scale of 1 to 10. Provide justification for your assessments.\n",
    "\n",
    "If the Expert has declined to answer, the rating for factual correctness is 1.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "192cc15a-9b0c-4d7f-b52f-ab24ff3c4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rater prompt\n",
    "ANSWER_PROMPT = \"\"\"\\\n",
    "You are a regulatory expert from a central bank who is reponsible for answering questions coming from commercial banks.\n",
    "You will get a question and context which is required for providing the data. Include references to regulatory sources \n",
    "when you provide opinions in a way that it would be clear on which paragraphs do you base your answer.\n",
    "\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[Question]: {question}\n",
    "************\n",
    "[Context]: {context}\n",
    "************\n",
    "[General information]: {general_info}\n",
    "************\n",
    "[END DATA]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb668f9-cd4a-4e9c-8c9d-fab5ae5f1190",
   "metadata": {},
   "source": [
    "### B. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0873be81-14c7-4862-8d6d-54f4f45eca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_rater(question, context, output, expected):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": RATER_PROMPT.format(question=question, context=context, output=output, expected=expected),\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"rate\",\n",
    "                    \"description\": \"Rate correctness on a scale of 1 to 10. Rate clarity on a scale of 1 to 10. Provide justification.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"correctness_rating\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 10},\n",
    "                            \"clarity_rating\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 10},\n",
    "                            \"justification\": {\"type\": \"string\"},\n",
    "                        },\n",
    "                        \"required\": [\"correctness_rating\", \"clarity_rating\", \"justification\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"rate\"}},\n",
    "    )\n",
    "    arguments = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "    return (arguments[\"correctness_rating\"], arguments[\"clarity_rating\"], arguments[\"justification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f058ecfc-6d31-4926-a5ff-8616ff4bd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, context, general_info):\n",
    "    o1_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": ANSWER_PROMPT.format(question=question, context=context, general_info=general_info),\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = wrap_long_lines(o1_response.choices[0].message.content, width=100)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d2b022-7a82-42fc-a214-58e1b554cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_long_lines(text, width=100):\n",
    "    lines = text.split('\\n')\n",
    "    wrapped_lines = []\n",
    "    for line in lines:\n",
    "        wrapped_lines.extend(textwrap.wrap(line, width=width))\n",
    "    return '\\n'.join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964fb3e1-1da8-497d-9b2b-d526575f4ab9",
   "metadata": {},
   "source": [
    "### C. Answer and rate questions from the EBA Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ebcb2c-b4b3-4519-8883-d6243f1ec197",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dod_eba.yaml', 'r', encoding='utf-8') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "with open('general_knowledge.yaml', 'r', encoding='utf-8') as f:\n",
    "    general_info = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5061c092-b107-4c23-b630-a48bc8681cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for item in data:\n",
    "    question = item[\"question\"]\n",
    "    context = item[\"context\"]\n",
    "    expected = item.get(\"answer\", \"\")\n",
    "    output = answer_question(question, context, general_info)\n",
    "    correctness_rating, clarity_rating, justification = numeric_rater(question, context, output, expected)\n",
    "    \n",
    "    results.append({\n",
    "        \"id\": item[\"question_id\"],\n",
    "        \"question\": question,\n",
    "        \"context\": context,\n",
    "        \"openai_answer\": output,\n",
    "        \"true_answer\": expected,\n",
    "        \"correctness_rating\": correctness_rating,\n",
    "        \"clarity_rating\": clarity_rating,\n",
    "        \"justification\": wrap_long_lines(justification, 100),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be8287f-a8f7-43db-8000-0af9465306aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>openai_answer</th>\n",
       "      <th>true_answer</th>\n",
       "      <th>correctness_rating</th>\n",
       "      <th>clarity_rating</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20247108</td>\n",
       "      <td>As for non-recourse factoring, is it correct t...</td>\n",
       "      <td>Not applicable\\n</td>\n",
       "      <td>In the context of non-recourse factoring, it i...</td>\n",
       "      <td>This question has been rejected because the is...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>The expert has declined to answer the question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20216045</td>\n",
       "      <td>Which NPV loss should be taken in order to cal...</td>\n",
       "      <td>paragraph 49 of EBA/GL/2016/07 &gt;&gt;&gt; For the pur...</td>\n",
       "      <td>To determine the net present value (NPV) loss ...</td>\n",
       "      <td>According to paragraph 51 of EBA/GL/2016/07 fo...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>The submitted answer accurately reflects the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20215754</td>\n",
       "      <td>For the treatment of cured defaulted exposures...</td>\n",
       "      <td>Source 1: CRR Article 178 &gt; Default of an obli...</td>\n",
       "      <td>Based on the provided context, the treatment o...</td>\n",
       "      <td>Minimum conditions for reclassification of a d...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>The submitted answer accurately reflects the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20205380</td>\n",
       "      <td>When applying the default at obligor level for...</td>\n",
       "      <td>Paragraph 104 of EBA/GL/2016/07 &gt;&gt;&gt;\\nA joint o...</td>\n",
       "      <td>In the context of applying the default at obli...</td>\n",
       "      <td>The first sentence of paragraph 104 of the Gui...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>The submitted answer aligns closely with the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20205357</td>\n",
       "      <td>Under the standardised method, in the context ...</td>\n",
       "      <td>CRR Article 134 &gt;&gt;&gt;\\n\\n1.   Tangible assets wi...</td>\n",
       "      <td>In the context of equipment leasing, such as v...</td>\n",
       "      <td>In accordance with Article 178(1)( b) of Regul...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>The submitted answer aligns well with the expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20194666</td>\n",
       "      <td>How to apply Article 123(c) CRR to set the abs...</td>\n",
       "      <td>Source 1: CRR Article 178 &gt; Default of an obli...</td>\n",
       "      <td>To apply Article 123(c) of the Capital Require...</td>\n",
       "      <td>For all past-due exposures, at any point in ti...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>The submitted answer accurately captures the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20184431</td>\n",
       "      <td>Do the requirements established in the Guideli...</td>\n",
       "      <td>Paragraph 95 of EBA/GL/2016/07 &gt;&gt;&gt;\\nApplicatio...</td>\n",
       "      <td>Based on the information from the Guidelines o...</td>\n",
       "      <td>Paragraphs 95 and following of the EBA guideli...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>The submitted answer aligns well with the expe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           question  \\\n",
       "0  20247108  As for non-recourse factoring, is it correct t...   \n",
       "1  20216045  Which NPV loss should be taken in order to cal...   \n",
       "2  20215754  For the treatment of cured defaulted exposures...   \n",
       "3  20205380  When applying the default at obligor level for...   \n",
       "4  20205357  Under the standardised method, in the context ...   \n",
       "5  20194666  How to apply Article 123(c) CRR to set the abs...   \n",
       "6  20184431  Do the requirements established in the Guideli...   \n",
       "\n",
       "                                             context  \\\n",
       "0                                   Not applicable\\n   \n",
       "1  paragraph 49 of EBA/GL/2016/07 >>> For the pur...   \n",
       "2  Source 1: CRR Article 178 > Default of an obli...   \n",
       "3  Paragraph 104 of EBA/GL/2016/07 >>>\\nA joint o...   \n",
       "4  CRR Article 134 >>>\\n\\n1.   Tangible assets wi...   \n",
       "5  Source 1: CRR Article 178 > Default of an obli...   \n",
       "6  Paragraph 95 of EBA/GL/2016/07 >>>\\nApplicatio...   \n",
       "\n",
       "                                       openai_answer  \\\n",
       "0  In the context of non-recourse factoring, it i...   \n",
       "1  To determine the net present value (NPV) loss ...   \n",
       "2  Based on the provided context, the treatment o...   \n",
       "3  In the context of applying the default at obli...   \n",
       "4  In the context of equipment leasing, such as v...   \n",
       "5  To apply Article 123(c) of the Capital Require...   \n",
       "6  Based on the information from the Guidelines o...   \n",
       "\n",
       "                                         true_answer  correctness_rating  \\\n",
       "0  This question has been rejected because the is...                   1   \n",
       "1  According to paragraph 51 of EBA/GL/2016/07 fo...                   9   \n",
       "2  Minimum conditions for reclassification of a d...                  10   \n",
       "3  The first sentence of paragraph 104 of the Gui...                   9   \n",
       "4  In accordance with Article 178(1)( b) of Regul...                   9   \n",
       "5  For all past-due exposures, at any point in ti...                   8   \n",
       "6  Paragraphs 95 and following of the EBA guideli...                   8   \n",
       "\n",
       "   clarity_rating                                      justification  \n",
       "0               8  The expert has declined to answer the question...  \n",
       "1               9  The submitted answer accurately reflects the e...  \n",
       "2               9  The submitted answer accurately reflects the e...  \n",
       "3               9  The submitted answer aligns closely with the e...  \n",
       "4               8  The submitted answer aligns well with the expe...  \n",
       "5               9  The submitted answer accurately captures the e...  \n",
       "6               9  The submitted answer aligns well with the expe...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ebb39-27fc-455d-90c7-668efa0c9525",
   "metadata": {},
   "source": [
    "### D. Show selected answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd5fb769-21ab-4abb-a456-5c4066e4024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### 1. Question ######### \n",
      "Under the standardised method, in the context of equipment leasing (vehicle\n",
      "lease), if more than three months of the lease are unpaid, must the default\n",
      "definition be applied to these due and unpaid payments of the lease only, or\n",
      "is it essential that a default contagion be applied to all projected lease\n",
      "payments which are not yet due (minimum payments provided for in the\n",
      "lease: see Article 134(7) CRR)?\n",
      "\n",
      "######### 2. OpenAI answer ######### \n",
      "In the context of equipment leasing, such as vehicle leases, when considering the application of the\n",
      "definition of default under the standardised method, we must refer to Article 178 of the Capital\n",
      "Requirements Regulation (CRR), which outlines the conditions under which a default is deemed to\n",
      "occur.\n",
      "According to CRR Article 178(1), a default is considered to have occurred when either the\n",
      "institution deems the obligor unlikely to pay its credit obligations in full, or when the obligor is\n",
      "more than 90 days past due on any material credit obligation. This would mean that if lease payments\n",
      "have been unpaid for more than three months (approximately 90 days), a default event may be\n",
      "triggered.\n",
      "Furthermore, the default definition's application to leases should consider all obligations under\n",
      "the lease contract, not just those that are currently due and unpaid. This is supported by the\n",
      "generalized application of default across all relevant obligations of the obligor, especially\n",
      "delineated for corporate exposures where default is applied at the obligor level. This concept can\n",
      "be extended to the notion of \"default contagion,\" which refers to the treatment of all obligations\n",
      "by the same obligor as in default once a particular obligation is deemed to be in default.\n",
      "For practical application:\n",
      "- The default should generally be applied at the level of the entire lease exposure and affect all\n",
      "projected lease payments, based on CRR Article 178 and considering guidelines on the definition of\n",
      "default which emphasize consistency across obligations.\n",
      "- According to the guidelines on the definition of default, for retail exposures, institutions have\n",
      "the flexibility to apply default at the facility level. However, consistency is key; if a payment\n",
      "defaults, it can affect other related obligations associated with the same obligor.\n",
      "Therefore, based on CRR Article 178, if a vehicle lease has payments unpaid for more than 90 days,\n",
      "it would trigger a default scenario that could potentially be applied to all projected lease\n",
      "payments, adhering to the principles of default contagion unless inconsistency is justified by\n",
      "institution policies.\n",
      "\n",
      "######### 3. EBA answer ######### \n",
      "In accordance with Article 178(1)( b) of Regulation (EU) No. 575/2013\n",
      "(“CRR”), “a default shall be considered to have occurred with regard to a\n",
      "particular obligor when”, in particular, “the obligor is more than 90 days\n",
      "past due on any material credit obligation to the institution, the parent\n",
      "undertaking or any of its subsidiaries.”\n",
      "Unless the institution applies the definition of default at the level of an\n",
      "individual credit facility, as provided for by the second subparagraph of the\n",
      "same Article and paragraph to the respective exposures, it follows that in\n",
      "case of a default of the obligor in accordance with Article 178(1)(b) CRR all\n",
      "exposures towards that particular obligor shall be classified in default status.\n",
      "In case the definition of default is applied at the level of an individual credit\n",
      "facility as in accordance with Article 134(7) CRR, “the exposure value for\n",
      "leases shall be the discounted minimum lease payments”, irrespective of\n",
      "some lease payments being still not due, the exposure related to a given\n",
      "lease contract with any material payments past due for more than three\n",
      "months, or any other indication of unlikeliness to pay, is classified as in\n",
      "default.\n",
      "\n",
      "\n",
      "######### 4. OpenAI justification ######### \n",
      "The submitted answer aligns well with the expert's interpretation of the CRR Articles 178 and 134\n",
      "regarding the definition of default in the context of equipment leasing. Both answers correctly\n",
      "identify that a default occurs when payments are more than 90 days overdue, and both discuss the\n",
      "application of default contagion to all obligations of the obligor. The submission also correctly\n",
      "notes the flexibility for retail exposures to apply default at the facility level, as mentioned in\n",
      "the expert answer. However, the submission could be clearer in explaining the specific application\n",
      "of Article 134(7) regarding the exposure value for leases, which the expert answer addresses more\n",
      "directly. Overall, the factual content is accurate, but the clarity could be improved by more\n",
      "directly linking the specific articles to the conclusions drawn.\n"
     ]
    }
   ],
   "source": [
    "# Show individual answers\n",
    "id = 4\n",
    "\n",
    "# Display a question\n",
    "print(\"######### 1. Question ######### \")\n",
    "print(df.at[id, 'question'].replace(\"\\\\n\", \"\\n\"))\n",
    "\n",
    "# Display an OpenAI answer\n",
    "print(\"######### 2. OpenAI answer ######### \")\n",
    "print(df.at[id, 'openai_answer'].replace(\"\\\\n\", \"\\n\"))\n",
    "\n",
    "# Display EBA answer\n",
    "print(\"\\n######### 3. EBA answer ######### \")\n",
    "print(df.at[id, 'true_answer'].replace(\"\\\\n\", \"\\n\"))\n",
    "\n",
    "# Display OpenAI justification\n",
    "print(\"\\n######### 4. OpenAI justification ######### \")\n",
    "print(df.at[id, 'justification'].replace(\"\\\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32236490-5e2b-4002-938e-577dffff6cdf",
   "metadata": {},
   "source": [
    "### E. Additional info on evaluating answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ab6ec-5603-457e-81b2-39ffcdfa4ef0",
   "metadata": {},
   "source": [
    "https://github.com/redhat-et/foundation-models-for-documentation/blob/master/notebooks/llm-evaluation/QA_evaluation_metrics_demo.ipynb\n",
    "\n",
    "**Human Evaluation**\n",
    "Human evaluation is a widely recognized approach for assessing the quality of generated answers in comparison to real ones. This paper highlights some current trends and best practice guidelines. Here are some steps to summarize the process,\n",
    "\n",
    "**Best Practices for Human Evaluation Planning:**\n",
    "\n",
    "Define the evaluation goal: Clearly articulate the research question and determine if there are specific hypotheses to test. Choose strong and representative baselines for comparison.\n",
    "Determine the type of evaluation: Decide whether the evaluation will be intrinsic or extrinsic, and consider the real-world or lab setting based on the goals and constraints.\n",
    "Choose the type of research: Opt for qualitative research to improve the system or quantitative research to assess the system's merit.\n",
    "Define constructs of interest: Decide whether to ask implementation questions or impact questions. Use separate criteria instead of an overall text quality construct. Provide formal definitions and concrete examples of the criteria in the instructions.\n",
    "Determine appropriate scales: For quantitative research, consider using multiple-item 7-point Likert scales or a ranking task to measure participant responses.\n",
    "Determine the sample: Recruit participants that reflect the target audience and provide a detailed description of their demographics. Use large-scale samples for quantitative research and calculate the minimum sample size required. Consider using multiple annotators for coding tasks.\n",
    "Specify the study's design: Prefer a within-subjects design over a between-subjects design if feasible. Keep the evaluation task simple and motivating, reduce practice and carryover effects, manage fatigue and order effects, and address nonresponse bias.\n",
    "Select a statistical approach: Use exploratory data analysis techniques for exploratory research, and employ statistical significance testing and report effect sizes when there are clear hypotheses.\n",
    "Optional: Consider preregistering the task if the evaluation is confirmatory.\n",
    "These recommendations provide guidance for planning human evaluations and ensuring robust and meaningful results.\n",
    "\n",
    "**While it offers valuable insights, there are several challenges associated with this method.**\n",
    "\n",
    "Subjectivity: Human judgments can be subjective, leading to inconsistencies in the evaluation process.\n",
    "Inter-rater agreement: Ensuring agreement among evaluators becomes crucial to minimize biases and maintain reliability.\n",
    "Scalability: Evaluating a large number of generated answers manually becomes impractical, requiring sampling techniques or statistical methods.\n",
    "Expertise and domain knowledge: Evaluators' expertise and knowledge can influence evaluation outcomes, necessitating clear guidelines and appropriate training.\n",
    "Cost and time: Conducting human evaluations can be costly and time-consuming, requiring resources for recruitment, compensation, and management.\n",
    "Biases: Evaluators may have personal preferences or biases that can impact the evaluation results.\n",
    "Automatic metrics, including BLEU scores, ROUGE scores, and others mentioned earlier, have been observed to have limited correlation with human evaluations when it comes to evaluating generated text (reference). Critics argue against relying on automated metrics for assessing linguistic properties and discourage their primary use. However, there are still benefits to utilizing automatic metrics in terms of cost-effectiveness, speed, and repeatability, which make them valuable for tasks like error analysis and system development. Although human evaluation is widely considered the gold standard for assessing overall system quality, conducting it extensively throughout the development process can be expensive and time-consuming.\n",
    "\n",
    "**Importance about Prompt**\n",
    "\n",
    "When evaluating the answers generated by a language model, it is crucial to consider the quality of the question or prompt provided to the model. The performance of language models heavily relies on the input they receive, and a well-crafted prompt can significantly influence their output. A good prompt provides clear instructions, includes relevant context, and specifies the desired format or type of response. It helps guide the language model towards generating accurate and coherent answers. Therefore, it is essential to pay attention to both the quality of the generated answers and the quality of the prompts used during evaluation to obtain reliable and meaningful results. By understanding the impact of prompts on language model performance, we can improve the effectiveness of evaluations and enhance the overall performance of language models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
